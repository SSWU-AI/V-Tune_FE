// src/components/ChatBotScreen.tsx
import React, { useRef, useState } from "react";
import { useNavigate } from "react-router-dom";
import { transcribeBlob } from "../api/googleSTT";
import { fetchGoogleTTS } from "../api/googleTTS";
import "../styles/ChatBotScreen.css";

import prevIcon from "../assets/icons/prev.svg";
import micIcon from "../assets/icons/mic.svg";
import stopIcon from "../assets/icons/stop.svg";
import sendIcon from "../assets/icons/send.svg";

type Msg = { role: "user" | "bot"; text: string };
type OAChatMsg = { role: "system" | "user" | "assistant"; content: string };

const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY as string;
const OPENAI_MODEL   = (import.meta.env.VITE_OPENAI_MODEL as string) || "gpt-4o-mini";
const OPENAI_BASE    = (import.meta.env.VITE_OPENAI_BASE as string) || "https://api.openai.com";
const GOOGLE_TTS_KEY = import.meta.env.VITE_GOOGLE_TTS_API_KEY as string;

function assertReady() {
  if (!OPENAI_API_KEY) throw new Error("VITE_OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
}

/* ---------- ìŠ¤íŠ¸ë ˆì¹­ í™”ë©´ìœ¼ë¡œ ë£¨í‹´ ì „ë‹¬ ---------- */
function setSelectedRoutineForStretching(routineId: number) {
  sessionStorage.setItem("stretchingRoutineId", String(routineId)); // 1..N
}

const routineNames = ["ì²™ì¶” ìœ ì—°ì„± ë£¨í‹´", "ëª¸í†µ ë¹„í‹€ê¸° ë£¨í‹´", "ì „ì‹  ì´ì™„ ë£¨í‹´", "í•˜ì²´ ê°•í™” ë£¨í‹´"];

/* ìˆ¨ê¹€ ë§ˆì»¤/ì •ë¦¬ */
const RID_RE = /\[\[\s*ROUTINE_ID\s*:\s*([1-4])\s*\]\]/i;
function stripRoutineMarker(s: string) { return s.replace(RID_RE, "").trim(); }

/* ë§ˆí¬ë‹¤ìš´ â†’ í‰ë¬¸ */
function toPlainText(raw: string) {
  let t = stripRoutineMarker(raw);
  t = t.replace(/```[\s\S]*?```/g, "");  // ì½”ë“œë¸”ë¡
  t = t.replace(/`[^`]*`/g, "");         // ì¸ë¼ì¸ì½”ë“œ
  t = t.replace(/\*\*([^*]+)\*\*/g, "$1").replace(/\*([^*]+)\*/g, "$1");
  t = t.replace(/__([^_]+)__/g, "$1").replace(/_([^_]+)_/g, "$1");
  t = t.replace(/~~([^~]+)~~/g, "$1");
  t = t.replace(/^\s*>+\s?/gm, "").replace(/^\s*#{1,6}\s*/gm, "");
  t = t.replace(/\n{3,}/g, "\n\n");
  return t.trim();
}

/* ë£¨í‹´ id ì¶”ì¶œ */
function extractRoutineIdFromText(text: string): number | null {
  const m = text.match(RID_RE); if (m) return Number(m[1]);
  const j = text.match(/"routine_id"\s*:\s*([1-4])/i); if (j) return Number(j[1]);
  const n = text.match(/(?:ë£¨í‹´\s*([1-4])|([1-4])\s*ë²ˆ\s*ë£¨í‹´)/); if (n) return Number(n[1] || n[2]);
  const nameMap: Record<number, RegExp> = {
    1: /(ì²™ì¶”\s*ìœ ì—°ì„±|ë‚™íƒ€|ìŸê¸°|ì•„ê¸°\s*ìì„¸|ìƒí–¥\s*í”Œë­í¬)/,
    2: /(ëª¸í†µ\s*ë¹„í‹€ê¸°|ì „êµ´\s*ìì„¸|ë¹„í‹€ë¦°|ì‚¼ê°ìì„¸)/,
    3: /(ì „ì‹ \s*ì´ì™„|ì—„ì§€ë°œê°€ë½|ê³ ì–‘ì´\s*ìì„¸|ë©”ëšœê¸°|ë¬´í•œ\s*ìì„¸)/,
    4: /(í•˜ì²´\s*ê°•í™”|ë¸Œë¦¿ì§€|ìŠ¤ì¿¼íŠ¸)/,
  };
  for (const id of [1,2,3,4] as const) if (nameMap[id].test(text)) return id;
  return null;
}

/* ìš´ë™ ì‹œì‘ ì˜ì‚¬ í™•ì¸ íŒ¨í„´ */
function isStartConfirmation(text: string): boolean {
  const confirmPatterns = [
    /ë„¤\s*,?\s*(ì‹œì‘|í•´ì£¼ì„¸ìš”|ì¢‹ì•„ìš”|ê·¸ë˜ìš”)/,
    /ì¢‹ì•„ìš”?\s*,?\s*(ì‹œì‘|í•´ì£¼ì„¸ìš”|ê·¸ë˜ìš”)/,
    /ì•Œê² ì–´ìš”?\s*,?\s*(ì‹œì‘|í•´ì£¼ì„¸ìš”)/,
    /ê·¸ë˜ìš”?\s*,?\s*(ì‹œì‘|í•´ì£¼ì„¸ìš”)/,
    /ì‘\s*,?\s*(ì‹œì‘|í•´ì£¼ì„¸ìš”|ì¢‹ì•„ìš”|ê·¸ë˜ìš”)/,
    /(ì‹œì‘|í•´ì£¼ì„¸ìš”|í• ê²Œìš”|í•˜ê² ì–´ìš”|ê³ ê³ )/,
    /^(ë„¤|ì‘|ì¢‹ì•„|ì•Œê² ì–´|ê·¸ë˜|yes|ok)$/i,
  ];
  return confirmPatterns.some(pattern => pattern.test(text.trim()));
}

const ChatBotScreen: React.FC = () => {
  const navigate = useNavigate();

  const [messages, setMessages] = useState<Msg[]>([
    { role: "bot", text: "ì•ˆë…•í•˜ì„¸ìš”! AI ìš´ë™ ì½”ì¹˜ì…ë‹ˆë‹¤.\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?" },
  ]);
  const [recording, setRecording] = useState(false);
  const [input, setInput] = useState("");
  const [voiceOn, setVoiceOn] = useState(true);
  const [thinking, setThinking] = useState(false);
  const [pendingRoutineId, setPendingRoutineId] = useState<number | null>(null); // ì‹œì‘ ëŒ€ê¸° ì¤‘ì¸ ë£¨í‹´

  // refs (í•œ ë²ˆë§Œ ì„ ì–¸)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const audioUrlRef = useRef<string | null>(null);

  const containerRef = useRef<HTMLDivElement | null>(null);
  const startXRef = useRef(0);
  const startYRef = useRef(0);
  const startTimeRef = useRef(0);
  const trackingRef = useRef(false);
  const EDGE = 24;   // ì™¼ìª½ ì—£ì§€ px
  const DIST = 80;   // ìµœì†Œ ê°€ë¡œ ì´ë™ px
  const MAX_DY = 40; // í—ˆìš© ì„¸ë¡œ í”ë“¤ë¦¼ px
  const MAX_MS = 600;// ì œìŠ¤ì²˜ ìµœëŒ€ ì‹œê°„ ms
  const touchStartsOnForm = (el: EventTarget | null) =>
    !!(el as HTMLElement | null)?.closest("input,textarea,button");

  const onTouchStart = (e: React.TouchEvent) => {
    const t = e.touches[0];
    if (!t || touchStartsOnForm(e.target)) return;
    startXRef.current = t.clientX;
    startYRef.current = t.clientY;
    startTimeRef.current = e.timeStamp;
    trackingRef.current = t.clientX <= EDGE;
  };

  const onTouchMove = (e: React.TouchEvent) => {
    if (!trackingRef.current) return;
    const t = e.touches[0];
    if (!t) return;
    const dx = t.clientX - startXRef.current;
    const dy = Math.abs(t.clientY - startYRef.current);
    if (dx > 10 && dy < MAX_DY) e.preventDefault();
  };
    
  const onTouchEnd = (e: React.TouchEvent) => {
    if (!trackingRef.current) return;
    trackingRef.current = false;
    const t = e.changedTouches[0];
    if (!t) return;
    const dx = t.clientX - startXRef.current;
    const dy = Math.abs(t.clientY - startYRef.current);
    const dt = e.timeStamp - startTimeRef.current;
    if (dx >= DIST && dy <= MAX_DY && dt <= MAX_MS) {
        cleanupAudio();
        navigate("/");
    }
  };

  const cleanupAudio = () => {
    if (audioRef.current) { audioRef.current.pause(); audioRef.current.src = ""; }
    if (audioUrlRef.current) { URL.revokeObjectURL(audioUrlRef.current); audioUrlRef.current = null; }
  };

  const playBase64Mp3 = async (base64: string) => {
    cleanupAudio();
    const bytes = Uint8Array.from(atob(base64), c => c.charCodeAt(0));
    const url = URL.createObjectURL(new Blob([bytes], { type: "audio/mpeg" }));
    audioUrlRef.current = url;
    if (!audioRef.current) audioRef.current = new Audio();
    audioRef.current.src = url;
    try { await audioRef.current.play(); } catch (error) {
      console.warn("Audio play failed:", error);
    }
  };

  /* ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ */
  const toOpenAIMessages = (msgs: Msg[]): OAChatMsg[] => {
    const system: OAChatMsg = {
      role: "system",
      content: `ë‹¹ì‹ ì€ í•œêµ­ì–´ ìš´ë™ ì½”ì¹˜ì…ë‹ˆë‹¤. ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ, ê°„ê²°í•˜ê²Œ ì•ˆë‚´í•˜ì„¸ìš”.
- ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€(ì½”ë“œë¸”ë¡/ë°±í‹±/*/**/_/~/#/>, ì´ëª¨ì§€ ê¸ˆì§€).
- íšŸìˆ˜/ì‹œê°„/ì„¸íŠ¸/ìœ ì§€/í˜¸í¡ ìˆ«ìëŠ” ì ˆëŒ€ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì•„ë˜ í˜•ì‹ì„ **ì •í™•íˆ** ë”°ë¦…ë‹ˆë‹¤.

[í˜•ì‹]
1ì¤„: "<ë£¨í‹´ ì´ë¦„(ë²ˆí˜¸)>ì„ ì¶”ì²œë“œë¦´ê²Œìš”. â€” <ì§§ì€ ì´ìœ >."
2ì¤„: "ì´ ë£¨í‹´ì€ ë‹¤ìŒì˜ ìš´ë™ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆì–´ìš”."
3~6ì¤„: 1) ìš´ë™ëª…
       2) ìš´ë™ëª…
       3) ìš´ë™ëª…
       4) ìš´ë™ëª…
7ì¤„: (ì§§ì€ ë§ˆë¬´ë¦¬ í•œ ë¬¸ì¥)

- ë‹µë³€ ë§¨ ë(ë§ˆì§€ë§‰ ì¤„ ë’¤ ê³µë°±)ì— [[ROUTINE_ID:n]] ë§ˆì»¤ë¥¼ ë°˜ë“œì‹œ ë¶™ì´ì„¸ìš”. (ì‚¬ìš©ìì—ê² ë³´ì´ì§€ ì•ŠìŒ)

ê°€ëŠ¥í•œ ë£¨í‹´:
  1. ì²™ì¶” ìœ ì—°ì„± ë£¨í‹´ â€” ë‚™íƒ€ ìì„¸/ìŸê¸° ìì„¸/ì•„ê¸° ìì„¸/ìƒí–¥ í”Œë­í¬ ìì„¸
  2. ëª¸í†µ ë¹„í‹€ê¸° ë£¨í‹´ â€” ì „êµ´ ìì„¸/ë¹„í‹€ë¦° ë¬´ë¦-ë¨¸ë¦¬ ë‹¿ê¸° ìì„¸/ë¹„í‹€ë¦° ë°˜ë‹¤ë¦¬ ë²Œë¦¬ê¸° ì „êµ´ ìì„¸/ë¹„í‹€ë¦° ì‚¼ê° ìì„¸
  3. ì „ì‹  ì´ì™„ ë£¨í‹´ â€” ì—„ì§€ë°œê°€ë½ ì¡ê¸° ìì„¸/ê³ ì–‘ì´ ìì„¸/ë©”ëšœê¸° ìì„¸/ë¬´í•œ ìì„¸
  4. í•˜ì²´ ê°•í™” ë£¨í‹´ â€” ë¸Œë¦¿ì§€ ìì„¸/ìŠ¤ì¿¼íŠ¸ ìì„¸/ì•„ê¸° ìì„¸/ìƒí–¥ í”Œë­í¬ ìì„¸`,
    };
    const mapped: OAChatMsg[] = msgs.map((m) => ({
      role: (m.role === "user" ? "user" : "assistant") as OAChatMsg["role"],
      content: m.text,
    }));
    return [system, ...mapped];
  };

  /* ---- ì „ì†¡ (ë¹„ìŠ¤íŠ¸ë¦¬ë°) ---- */
  const sendText = async (text: string) => {
    const trimmed = text.trim();
    if (!trimmed) return;

    // ìš´ë™ ì‹œì‘ í™•ì¸ ì¤‘ì´ê³  ê¸ì • ë‹µë³€ì¸ ê²½ìš°
    if (pendingRoutineId && isStartConfirmation(trimmed)) {
      setMessages(prev => [...prev, { role: "user", text: trimmed }]);
      
      const startMessage = `ì¢‹ìŠµë‹ˆë‹¤! ${routineNames[pendingRoutineId - 1]}ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.`;
      setMessages(prev => [...prev, { role: "bot", text: startMessage }]);
      
      if (voiceOn && GOOGLE_TTS_KEY) {
        try {
          const audioBase64 = await fetchGoogleTTS(startMessage, GOOGLE_TTS_KEY);
          if (audioBase64) await playBase64Mp3(audioBase64);
        } catch (err) {
          console.warn("TTS ì‹¤íŒ¨:", err);
        }
      }
      
      // sessionStorageì—ë„ ì €ì¥ (fallbackìš©)
      setSelectedRoutineForStretching(pendingRoutineId);
      
      const routineIdToPass = pendingRoutineId;
      setPendingRoutineId(null);
      
      // URL íŒŒë¼ë¯¸í„°ë¡œ ë£¨í‹´ ID ì „ë‹¬
      setTimeout(() => {
        cleanupAudio();
        navigate(`/stretch?routineId=${routineIdToPass}`);
      }, 1000);
      
      return;
    }

    setMessages(prev => [...prev, { role: "user", text: trimmed }, { role: "bot", text: "ğŸ¤– ìƒê° ì¤‘..." }]);
    setInput("");
    setThinking(true);
    setPendingRoutineId(null); // ìƒˆ ì§ˆë¬¸ì´ë¯€ë¡œ ëŒ€ê¸° ìƒíƒœ ì´ˆê¸°í™”

    try {
      const body = {
        model: OPENAI_MODEL,
        messages: toOpenAIMessages([...messages, { role: "user", text: trimmed }]),
        temperature: 0.6
      };

      assertReady();
      const res = await fetch(`${OPENAI_BASE}/v1/chat/completions`, {
        method: "POST",
        headers: { Authorization: `Bearer ${OPENAI_API_KEY}`, "Content-Type": "application/json" },
        body: JSON.stringify(body),
      });
      if (!res.ok) throw new Error(await res.text().catch(() => "ìš”ì²­ ì‹¤íŒ¨"));
      const data = await res.json();
      const raw = data?.choices?.[0]?.message?.content || "";

      const picked = extractRoutineIdFromText(raw);
      const finalText = toPlainText(raw);

      // ë§ˆì§€ë§‰ "ğŸ¤– ìƒê° ì¤‘..." ë²„ë¸”ì„ ìµœì¢… í…ìŠ¤íŠ¸ë¡œ êµì²´
      setMessages(prev => {
        const copy = [...prev];
        for (let i = copy.length - 1; i >= 0; i--) {
          if (copy[i].role === "bot" && copy[i].text === "ğŸ¤– ìƒê° ì¤‘...") {
            copy[i] = { role: "bot", text: finalText || "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆì–´ìš”." };
            break;
          }
        }
        return copy;
      });

      // ë£¨í‹´ì´ ì¶”ì²œëœ ê²½ìš° ìš´ë™ ì‹œì‘ ì˜ì‚¬ í™•ì¸ ë©”ì‹œì§€ ì¶”ê°€
      if (picked) {
        const confirmMessage = "ìš´ë™ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?";
        setTimeout(() => {
          setMessages(prev => [...prev, { role: "bot", text: confirmMessage }]);
          setPendingRoutineId(picked);
          
          // TTS: ì¶”ì²œ ë‚´ìš© + ì‹œì‘ í™•ì¸ ë©”ì‹œì§€
          const fullSpeech = [finalText, confirmMessage].join("\n");
          if (voiceOn && GOOGLE_TTS_KEY && fullSpeech) {
            fetchGoogleTTS(fullSpeech, GOOGLE_TTS_KEY)
              .then(audioBase64 => {
                if (audioBase64) return playBase64Mp3(audioBase64);
              })
              .catch(err => console.warn("TTS ì‹¤íŒ¨:", err));
          }
        }, 500);
      } else {
        // ë£¨í‹´ ì¶”ì²œì´ ì•„ë‹Œ ì¼ë°˜ ë‹µë³€ì˜ ê²½ìš° TTSë§Œ
        if (voiceOn && GOOGLE_TTS_KEY && finalText) {
          try {
            const audioBase64 = await fetchGoogleTTS(finalText, GOOGLE_TTS_KEY);
            if (audioBase64) await playBase64Mp3(audioBase64);
          } catch (err) {
            console.warn("TTS ì‹¤íŒ¨:", err);
          }
        }
      }
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : "ìš”ì²­ ì‹¤íŒ¨";
      setMessages(prev => {
        const copy = [...prev];
        for (let i = copy.length - 1; i >= 0; i--) {
          if (copy[i].role === "bot" && copy[i].text === "ğŸ¤– ìƒê° ì¤‘...") {
            copy[i] = { role: "bot", text: `âŒ ì˜¤ë¥˜: ${errorMessage}` };
            break;
          }
        }
        return copy;
      });
    } finally {
      setThinking(false);
    }
  };

  const handleSubmit = (e: React.FormEvent) => { e.preventDefault(); if (!thinking) sendText(input); };

  /* ---- STT ---- */
  const startSTT = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const mime = MediaRecorder.isTypeSupported("audio/webm") ? "audio/webm" : "audio/ogg";
    const mr = new MediaRecorder(stream, { mimeType: mime });
    mediaRecorderRef.current = mr;
    chunksRef.current = [];
    setRecording(true);
    setMessages(prev => [...prev, { role: "bot", text: "ğŸ™ ì¸ì‹ ì¤‘..." }]);

    mr.ondataavailable = (e) => { if (e.data.size > 0) chunksRef.current.push(e.data); };
    mr.onstop = async () => {
      const blob = new Blob(chunksRef.current, { type: mime });
      setMessages(prev => prev.filter(m => m.text !== "ğŸ™ ì¸ì‹ ì¤‘..."));
      setRecording(false);
      try {
        const { text } = await transcribeBlob(blob);
        await sendText((text || "").trim() || "(ì¸ì‹ ê²°ê³¼ ì—†ìŒ)");
      } catch (error) {
        console.warn("STT ì‹¤íŒ¨:", error);
        setMessages(prev => [...prev, { role: "bot", text: "âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨" }]);
      }
    };
    mr.start();
  };
  const stopSTT = () => { mediaRecorderRef.current?.stop(); };

  return (
    <div
        ref={containerRef}
        className="chat-container"
        onTouchStart={onTouchStart}
        onTouchMove={onTouchMove}
        onTouchEnd={onTouchEnd}
    >
      {/* ìƒë‹¨ ë°” */}
      <div className="chat-topbar">
        <button
          onClick={() => { cleanupAudio(); navigate("/"); }}
          aria-label="ë’¤ë¡œê°€ê¸°"
          className="icon-btn"
          title="ë’¤ë¡œê°€ê¸°"
        >
          <img src={prevIcon} alt="back" className="icon-20" />
        </button>

        <h2 className="chat-title">V-Tune</h2>

        <div style={{ marginLeft: "auto" }}>
          <button
            type="button"
            onClick={() => setVoiceOn(v => !v)}
            title={voiceOn ? "ìŒì„± ë‹µë³€ ë„ê¸°" : "ìŒì„± ë‹µë³€ ì¼œê¸°"}
            className={`voice-toggle ${voiceOn ? "" : "off"}`}
          >
            {voiceOn ? "ğŸ”ˆ ìŒì„± On" : "ğŸ”‡ ìŒì„± Off"}
          </button>
        </div>
      </div>

      {/* ì±„íŒ… ì˜ì—­ */}
      <div className="chat-area">
        {messages.map((m, i) => (
          <div key={i} className={`bubble ${m.role}`}>
            {m.text}
          </div>
        ))}
      </div>

      {/* í•˜ë‹¨ ì…ë ¥/ìŒì„± ë°” */}
      <form onSubmit={handleSubmit} className="chat-inputbar">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder={thinking ? "AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..." : "AI ì½”ì¹˜ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"}
          disabled={thinking}
          className="chat-input"
        />

        <button
          type="button"
          onClick={recording ? stopSTT : startSTT}
          aria-label={recording ? "ì¸ì‹ ì¤‘ì§€" : "ìŒì„± ì¸ì‹ ì‹œì‘"}
          disabled={thinking}
          className="icon-btn"
          title={recording ? "ì¸ì‹ ì¤‘ì§€" : "ìŒì„± ì¸ì‹ ì‹œì‘"}
        >
          <img src={recording ? stopIcon : micIcon} alt="" className="icon-20" />
        </button>

        <button
          type="submit"
          aria-label="ë©”ì‹œì§€ ì „ì†¡"
          disabled={thinking}
          className="icon-btn"
          title="ì „ì†¡"
        >
          <img src={sendIcon} alt="send" className="icon-20" />
        </button>
      </form>
    </div>
  );
};

export default ChatBotScreen;