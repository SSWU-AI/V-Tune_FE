import React, { useEffect, useRef, useState, useCallback } from 'react';
import { fetchGoogleTTS } from '../api/googleTTS';
const apiKey = import.meta.env.VITE_GOOGLE_TTS_API_KEY;
import { useNavigate, useSearchParams } from 'react-router-dom';
import axios from 'axios';
import Webcam from 'react-webcam';
import { Pose, POSE_LANDMARKS, POSE_CONNECTIONS } from '@mediapipe/pose';
import type { Results } from '@mediapipe/pose';
import * as cam from '@mediapipe/camera_utils';
import '../styles/StretchScreen.css';

import prevIcon from '../assets/icons/prev.svg';
import personIcon from '../assets/icons/person.svg';
import Popup from './Popup';

const MAX_DOTS = 3;

interface PoseStep {
  id: number;
  step_number: number;
  keypoints: string;
  pose_description: string;
  exercise: number;
}

interface Exercise {
  exercise_id: number;
  name: string;
  description: string;
  repetition: number;
  order: number;
}

const REQUIRED_KEYS = [
  'NOSE', 'LEFT_SHOULDER', 'RIGHT_SHOULDER',
  'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST',
  'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE',
  'LEFT_ANKLE', 'RIGHT_ANKLE'
] as const;

const StretchScreen: React.FC = () => {
  const [step, setStep] = useState(1);
  const [sets, setSets] = useState(0);
  const [showPopup, setShowPopup] = useState(false);
  const [facingMode, setFacingMode] = useState<"user" | "environment">("user");
  const [exerciseName, setExerciseName] = useState('ë¡œë”© ì¤‘...');
  const [exerciseDesc, setExerciseDesc] = useState('í¬ì¦ˆ ì„¤ëª…ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...');
  const [poseSteps, setPoseSteps] = useState<PoseStep[]>([]);
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [exercises, setExercises] = useState<Exercise[]>([]);
  const [currentExerciseIndex, setCurrentExerciseIndex] = useState(0);
  const [isStepMatched, setIsStepMatched] = useState(false);

  // ìŒì„± ì¬ìƒ ìƒíƒœ
  const [isPlayingTTS, setIsPlayingTTS] = useState(false);
  const [hasFeedbackPlayed, setHasFeedbackPlayed] = useState(false);

  // ì¢Œí‘œ ì²˜ë¦¬ ê°„ê²©
  const lastProcessedTimeRef = useRef<number>(0);
  const PROCESS_INTERVAL = 15000; // 15ì´ˆ

  const navigate = useNavigate();
  const webcamRef = useRef<Webcam>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const cameraRef = useRef<cam.Camera | null>(null);
  const poseRef = useRef<Pose | null>(null);
  const [searchParams] = useSearchParams();

  // ìµœì‹  ìƒíƒœë¥¼ onResultsì—ì„œ ì•ˆì „í•˜ê²Œ ì½ê¸° ìœ„í•œ refs
  const isPlayingTTSRef = useRef(isPlayingTTS);
  const isStepMatchedRef = useRef(isStepMatched);
  const hasFeedbackPlayedRef = useRef(hasFeedbackPlayed);
  const exercisesRef = useRef(exercises);
  const currentExerciseIndexRef = useRef(currentExerciseIndex);
  const stepRef = useRef(step);

  useEffect(() => { isPlayingTTSRef.current = isPlayingTTS; }, [isPlayingTTS]);
  useEffect(() => { isStepMatchedRef.current = isStepMatched; }, [isStepMatched]);
  useEffect(() => { hasFeedbackPlayedRef.current = hasFeedbackPlayed; }, [hasFeedbackPlayed]);
  useEffect(() => { exercisesRef.current = exercises; }, [exercises]);
  useEffect(() => { currentExerciseIndexRef.current = currentExerciseIndex; }, [currentExerciseIndex]);
  useEffect(() => { stepRef.current = step; }, [step]);

  // --- TTS Queue/Manager ---
  type TTSType = 'feedback' | 'description';
  type TTSTask = { text: string; type: TTSType; resolve?: () => void; };

  const ttsQueueRef = useRef<TTSTask[]>([]);
  const ttsProcessingRef = useRef(false);
  const lastDescKeyRef = useRef<string>('');

  // ì˜¤ë””ì˜¤ í•¸ë“¤
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const descriptionAudioRef = useRef<HTMLAudioElement | null>(null);

  const stopAllTTS = () => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current = null;
    }
    if (descriptionAudioRef.current) {
      descriptionAudioRef.current.pause();
      descriptionAudioRef.current = null;
    }
    setIsPlayingTTS(false);
  };

  const internalPlay = useCallback(async (text: string, type: TTSType) => {
    try {
      setIsPlayingTTS(true);

      if (type === 'feedback' && currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }
      if (type === 'description' && descriptionAudioRef.current) {
        descriptionAudioRef.current.pause();
        descriptionAudioRef.current = null;
      }

      const audioContent = await fetchGoogleTTS(text, apiKey);
      if (!audioContent) {
        setIsPlayingTTS(false);
        return;
      }

      const audio = new Audio(`data:audio/mp3;base64,${audioContent}`);
      if (type === 'description') descriptionAudioRef.current = audio;
      else currentAudioRef.current = audio;

      await new Promise<void>((resolve, reject) => {
        audio.addEventListener('ended', () => {
          setIsPlayingTTS(false);
          if (type === 'description') descriptionAudioRef.current = null;
          else currentAudioRef.current = null;
          resolve();
        });
        audio.addEventListener('error', (e) => {
          setIsPlayingTTS(false);
          if (type === 'description') descriptionAudioRef.current = null;
          else currentAudioRef.current = null;
          reject(e);
        });
        audio.play().catch(reject);
      });
    } catch (e) {
      console.error('TTS ì¬ìƒ ì˜¤ë¥˜:', e);
      setIsPlayingTTS(false);
    }
  }, [apiKey]);

  const processQueue = useCallback(async () => {
    if (ttsProcessingRef.current) return;
    ttsProcessingRef.current = true;
    try {
      while (ttsQueueRef.current.length) {
        const task = ttsQueueRef.current.shift()!;
        await internalPlay(task.text, task.type);
        task.resolve?.();
        await new Promise(r => setTimeout(r, 80)); // ì•½ê°„ì˜ ì¸í„°ë²Œ
      }
    } finally {
      ttsProcessingRef.current = false;
    }
  }, [internalPlay]);

  const enqueueTTS = useCallback((text: string, type: TTSType) => {
    return new Promise<void>((resolve) => {
      if (!text) { resolve(); return; }

      if (type === 'feedback') {
        // ì„ ì : ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¤‘ë‹¨ + íë¥¼ í”¼ë“œë°±ìœ¼ë¡œ ê°ˆì•„ë¼ìš°ê¸°
        if (descriptionAudioRef.current) {
          descriptionAudioRef.current.pause();
          descriptionAudioRef.current = null;
        }
        if (currentAudioRef.current) {
          currentAudioRef.current.pause();
          currentAudioRef.current = null;
        }
        ttsQueueRef.current = [{ text, type, resolve }];
      } else {
        // description: ë™ì¼ í…ìŠ¤íŠ¸ ì¤‘ë³µ ëŒ€ê¸° ê¸ˆì§€
        const dupInQueue = ttsQueueRef.current.some(t => t.type === 'description' && t.text === text);
        const playingDesc = !!descriptionAudioRef.current;
        if (dupInQueue || playingDesc) { resolve(); return; }
        ttsQueueRef.current.push({ text, type, resolve });
      }

      processQueue();
    });
  }, [processQueue]);

  // ë‹¤ìŒ ìŠ¤í… ì´ë™
  const moveToNextStep = useCallback(() => {
    lastProcessedTimeRef.current = 0;

    const nextIndex = currentStepIndex + 1;

    if (nextIndex >= poseSteps.length) {
      const nextSets = Math.min(sets + 1, MAX_DOTS);
      setSets(nextSets);
      setCurrentStepIndex(0);
      setExerciseDesc(poseSteps[0]?.pose_description || 'í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
      setStep(poseSteps[0]?.step_number || 1);
      setIsStepMatched(false);
      setHasFeedbackPlayed(false);

      if (nextSets >= MAX_DOTS) {
        if (currentExerciseIndex + 1 < exercises.length) {
          setCurrentExerciseIndex(prev => prev + 1);
        } else {
          setShowPopup(true);
          setTimeout(() => {
            navigate('/record');
          }, 3000);
        }
      }
    } else {
      setCurrentStepIndex(nextIndex);
      setExerciseDesc(poseSteps[nextIndex].pose_description);
      setStep(poseSteps[nextIndex].step_number);
      setIsStepMatched(false);
      setHasFeedbackPlayed(false);
    }
  }, [currentStepIndex, poseSteps, sets, currentExerciseIndex, exercises, navigate]);

  // ìš´ë™/í¬ì¦ˆ ì„¤ëª… ë¡œë”©
  useEffect(() => {
    const routineId = searchParams.get('routineId');
    
    // URL íŒŒë¼ë¯¸í„°ì—ì„œ routineIdë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° sessionStorageì—ì„œ í™•ì¸
    const finalRoutineId = routineId || sessionStorage.getItem("stretchingRoutineId");
    
    if (!finalRoutineId) {
      console.error('ë£¨í‹´ IDê°€ ì—†ìŠµë‹ˆë‹¤.');
      // í™ˆìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
      navigate('/');
      return;
    }

    console.log('ì‚¬ìš©í•  ë£¨í‹´ ID:', finalRoutineId);

    const fetchExerciseAndPoseDesc = async () => {
      try {
        const response = await axios.get(
          `https://v-tune-be.onrender.com/api/routines/${finalRoutineId}/exercises/`
        );

        const exerciseList = response.data.exercises;
        if (Array.isArray(exerciseList) && exerciseList.length > 0) {
          setExercises(exerciseList);

          const currentExercise = exerciseList[currentExerciseIndex];
          setExerciseName(currentExercise?.name || 'ìš´ë™ ì´ë¦„ ì—†ìŒ');

          await loadPoseSteps(currentExercise.exercise_id);
        } else {
          setExerciseName('ìš´ë™ ì´ë¦„ ì—†ìŒ');
          setExerciseDesc('í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
        }
      } catch (error) {
        console.error('ìš´ë™ ì •ë³´ ë˜ëŠ” í¬ì¦ˆ ì„¤ëª… ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', error);
        setExerciseName('ìš´ë™ ì´ë¦„ ì—†ìŒ');
        setExerciseDesc('í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
      }
    };

    fetchExerciseAndPoseDesc();
  }, [searchParams, currentExerciseIndex, navigate]);

  // í¬ì¦ˆ ìŠ¤í… ë¡œë”©
  const loadPoseSteps = async (exerciseId: number) => {
    try {
      const poseStepRes = await axios.get(
        `https://v-tune-be.onrender.com/api/data/pose-steps/?exercise_id=${exerciseId}`
      );

      if (Array.isArray(poseStepRes.data) && poseStepRes.data.length > 0) {
        const steps = poseStepRes.data;
        setPoseSteps(steps);

        setExerciseDesc(steps[0].pose_description || 'í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
        setStep(steps[0].step_number);
        setCurrentStepIndex(0);
        setSets(0);
        setHasFeedbackPlayed(false);

        console.log('ì´ ìŠ¤í… ìˆ˜:', steps.length);
        console.log('ë§ˆì§€ë§‰ ìŠ¤í… ë²ˆí˜¸:', steps[steps.length - 1].step_number);
      } else {
        setExerciseDesc('í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
      }
    } catch (error) {
      console.error('í¬ì¦ˆ ìŠ¤í… ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', error);
      setExerciseDesc('í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
    }
  };

  // ê²°ê³¼ ì²˜ë¦¬ & ê·¸ë¦¬ê¸° & ë¹„êµ í˜¸ì¶œ
  const onResults = useCallback(async (results: Results) => {
    if (!results.poseLandmarks) return;

    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    const video = webcamRef.current?.video;
    if (!ctx || !canvas || !video) return;

    // ìº”ë²„ìŠ¤ ì‚¬ì´ì¦ˆ & í´ë¦¬ì–´
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // ì—°ê²°ì„ 
    for (const [startIdx, endIdx] of POSE_CONNECTIONS) {
      const start = results.poseLandmarks[startIdx];
      const end = results.poseLandmarks[endIdx];
      if (!start || !end) continue;

      ctx.beginPath();
      ctx.moveTo(start.x * canvas.width, start.y * canvas.height);
      ctx.lineTo(end.x * canvas.width, end.y * canvas.height);
      ctx.strokeStyle = '#00FF88';
      ctx.lineWidth = 2;
      ctx.stroke();
    }

    // í¬ì¸íŠ¸
    for (const pt of results.poseLandmarks) {
      ctx.beginPath();
      ctx.arc(pt.x * canvas.width, pt.y * canvas.height, 4, 0, 2 * Math.PI);
      ctx.fillStyle = '#00FF88';
      ctx.fill();
    }

    // ë°±ì—”ë“œ í˜¸ì¶œ ì¡°ê±´ (ê·¸ë¦¬ê¸°ëŠ” í•­ìƒ ì§„í–‰)
    const currentTime = Date.now();
    const shouldProcessPose = currentTime - lastProcessedTimeRef.current >= PROCESS_INTERVAL;

    if (!shouldProcessPose) return;
    if (isStepMatchedRef.current) return;
    if (isPlayingTTSRef.current) return;

    lastProcessedTimeRef.current = currentTime;
    console.log('15ì´ˆ ê°„ê²©ìœ¼ë¡œ í¬ì¦ˆ ë¶„ì„ ì‹¤í–‰');

    // í•„ìˆ˜ í‚¤ë§Œ ì •í™•í•œ ì¸ë±ìŠ¤ë¡œ í•„í„°ë§
    const filteredKeypoints: Record<string, [number, number]> = {};
    for (const name of REQUIRED_KEYS) {
      const idx = (POSE_LANDMARKS as Record<string, number>)[name];
      const lm = results.poseLandmarks[idx];
      if (lm) filteredKeypoints[name] = [lm.x, lm.y];
    }

    try {
      const exIdx = currentExerciseIndexRef.current;
      const currentEx = exercisesRef.current[exIdx];

      if (!currentEx?.exercise_id) {
        console.error('exercise_idê°€ ì—†ì–´ì„œ ë°±ì—”ë“œ ìš”ì²­ì„ ê±´ë„ˆëœë‹ˆë‹¤.');
        return;
      }

      const response = await axios.post(
        'https://v-tune-be.onrender.com/api/compare/',
        { keypoints: filteredKeypoints },
        {
          params: {
            exercise_id: currentEx.exercise_id,
            step_number: stepRef.current
          },
          headers: { "Content-Type": "application/json" }
        }
      );

      console.log('ë°±ì—”ë“œ ì‘ë‹µ:', response.data);
      const feedbackText =
        response.data.feedback_text ||
        response.data.ck_text ||
        (response.data.match ? "ì •ë‹µì…ë‹ˆë‹¤" : "ìì„¸ë¥¼ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ ì£¼ì„¸ìš”");

      if (response.data.match) {
        if (!hasFeedbackPlayedRef.current) {
          hasFeedbackPlayedRef.current = true;
          setHasFeedbackPlayed(true);
          setIsStepMatched(true);

          // í”¼ë“œë°± ëë‚œ ë’¤ ë‹¤ìŒ ìŠ¤í…
          enqueueTTS(feedbackText, 'feedback')
            .then(() => setTimeout(moveToNextStep, 500))
            .catch(() => setTimeout(moveToNextStep, 500));
        }
      } else {
        if (!hasFeedbackPlayedRef.current) {
          hasFeedbackPlayedRef.current = true;
          setHasFeedbackPlayed(true);
          enqueueTTS(feedbackText, 'feedback')
            .then(() => {
              setTimeout(() => {
                hasFeedbackPlayedRef.current = false;
                setHasFeedbackPlayed(false);
              }, 2000);
            })
            .catch(() => {
              hasFeedbackPlayedRef.current = false;
              setHasFeedbackPlayed(false);
            });
        }
        console.log('ì •ë‹µì´ ì•„ë‹™ë‹ˆë‹¤');
      }
    } catch (error) {
      console.error('ë°±ì—”ë“œ API ì˜¤ë¥˜:', error);
    }
  }, [enqueueTTS, moveToNextStep]);

  // ìµœì‹  onResultsë¥¼ Poseì— ì—°ê²°í•˜ê¸° ìœ„í•œ ref
  const onResultsRef = useRef<(r: Results) => void>(() => {});
  useEffect(() => { onResultsRef.current = onResults; }, [onResults]);

  // PoseëŠ” 1íšŒë§Œ ìƒì„±
  useEffect(() => {
    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    pose.onResults((res: Results) => onResultsRef.current(res));
    poseRef.current = pose;

    return () => {
      poseRef.current?.close();
      poseRef.current = null;
    };
  }, []);

  // ì¹´ë©”ë¼ëŠ” ì „/í›„ë©´ ì „í™˜ ì‹œì—ë§Œ ì¬ì‹œì‘
  useEffect(() => {
    const startCamera = () => {
      if (
        typeof webcamRef.current !== "undefined" &&
        webcamRef.current !== null &&
        webcamRef.current.video !== null &&
        poseRef.current
      ) {
        cameraRef.current = new cam.Camera(webcamRef.current.video!, {
          onFrame: async () => {
            if (poseRef.current && webcamRef.current?.video) {
              await poseRef.current.send({ image: webcamRef.current.video });
            }
          },
          width: 640,
          height: 480,
        });
        cameraRef.current.start();
      }
    };

    startCamera();
    return () => {
      cameraRef.current?.stop();
      cameraRef.current = null;
    };
  }, [facingMode]);

  const toggleCamera = useCallback(() => {
    setFacingMode(prev => (prev === "user" ? "environment" : "user"));
  }, []);

  // ì„¤ëª… TTS (ì¤‘ë³µ ë°©ì§€ + í)
  useEffect(() => {
    if (!exerciseDesc) return;

    const currentEx = exercises[currentExerciseIndex];
    const descKey = `${currentEx?.exercise_id ?? 'x'}-${step}-${exerciseDesc}`;
    if (lastDescKeyRef.current === descKey) return; // ê°™ì€ ì„¤ëª…ì´ë©´ íŒ¨ìŠ¤
    lastDescKeyRef.current = descKey;

    const timer = setTimeout(() => {
      enqueueTTS(exerciseDesc, 'description').catch(() => {});
    }, 400);

    return () => clearTimeout(timer);
  }, [exerciseDesc, step, currentExerciseIndex, exercises, enqueueTTS]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ TTS ì •ë¦¬
  useEffect(() => {
    return () => {
      stopAllTTS();
    };
  }, []);

  return (
    <div className="stretch-container">
      <div className="top-bar">
        <button onClick={() => navigate('/')}>
          <img src={prevIcon} alt="Previous" />
        </button>
        <h2>{exerciseName}</h2>
      </div>

      <div className="camera-card" onClick={toggleCamera}>
        <div className="camera-wrapper">
          <Webcam
            key={facingMode}
            ref={webcamRef}
            className="camera"
            videoConstraints={{ facingMode }}
            // ì¢Œìš°ë°˜ì „(ë¯¸ëŸ¬ë§) ë¯¸ì ìš©
          />
          <canvas
            ref={canvasRef}
            className="pose-canvas"
            style={{
              position: 'absolute',
              top: 0,
              left: 0,
              zIndex: 2,
              width: '100%',
              height: '100%',
              pointerEvents: 'none',
            }}
          />
          <div className="overlay-box">
            <div className="set-count">
              <div className="dots">
                {[...Array(Math.min(sets, MAX_DOTS))].map((_, i) => (
                  <div key={i} className="dot" />
                ))}
              </div>
              <div className="reps">Step<br />{step}</div>
            </div>
          </div>
          {showPopup && <Popup />}
        </div>
      </div>

      <div className="description-balloon">
        <img src={personIcon} alt="person" className="person-icon" />
        <div className="custom-balloon">
          {exerciseDesc}
          {isPlayingTTS && <div className="playing-indicator">ğŸ”Š</div>}
        </div>
      </div>
    </div>
  );
};

export default StretchScreen;