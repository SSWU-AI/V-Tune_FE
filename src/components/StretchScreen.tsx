import React, { useEffect, useRef, useState, useCallback } from 'react';
import { fetchGoogleTTS } from '../api/googleTTS';
const apiKey = import.meta.env.VITE_GOOGLE_TTS_API_KEY;
import { useNavigate, useSearchParams } from 'react-router-dom';
import axios from 'axios';
import Webcam from 'react-webcam';
import { Pose, POSE_LANDMARKS, POSE_CONNECTIONS } from '@mediapipe/pose';
import type { Results, Landmark } from '@mediapipe/pose';
import * as cam from '@mediapipe/camera_utils';
import '../styles/StretchScreen.css';

import prevIcon from '../assets/icons/prev.svg';
import personIcon from '../assets/icons/person.svg';
import Popup from './Popup';

const MAX_DOTS = 3;

// íƒ€ì´ë° ì„¤ì •
const POSE_WAIT_TIME = 10000;       // 10ì´ˆ - ìš´ë™ ì„¤ëª… í›„ ìì„¸ ëŒ€ê¸°
const NEXT_STEP_WAIT_TIME = 3000;   // 3ì´ˆ - (ì •ë‹µ) í”¼ë“œë°± í›„ ë‹¤ìŒ ìŠ¤í… ëŒ€ê¸°

interface PoseStep {
  id: number;
  step_number: number;
  keypoints: string;
  pose_description: string;
  exercise: number;
}

interface Exercise {
  exercise_id: number;
  name: string;
  description: string;
  repetition: number;
  order: number;
}

const REQUIRED_KEYS = [
  'NOSE', 'LEFT_SHOULDER', 'RIGHT_SHOULDER',
  'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST',
  'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE',
  'LEFT_ANKLE', 'RIGHT_ANKLE'
] as const;

const StretchScreen: React.FC = () => {
  const [step, setStep] = useState(1);
  const [sets, setSets] = useState(0);
  const [showPopup, setShowPopup] = useState(false);
  const [facingMode, setFacingMode] = useState<"user" | "environment">("user");
  const [exerciseName, setExerciseName] = useState('ë¡œë”© ì¤‘...');
  const [exerciseDesc, setExerciseDesc] = useState('í¬ì¦ˆ ì„¤ëª…ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...');
  const [poseSteps, setPoseSteps] = useState<PoseStep[]>([]);
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [exercises, setExercises] = useState<Exercise[]>([]);
  const [currentExerciseIndex, setCurrentExerciseIndex] = useState(0);
  
  const [isPlayingTTS, setIsPlayingTTS] = useState(false);
  const [currentPhase, setCurrentPhase] =
    useState<'loading' | 'description' | 'waiting' | 'feedback' | 'moving'>('loading');

  const navigate = useNavigate();
  const webcamRef = useRef<Webcam>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const cameraRef = useRef<cam.Camera | null>(null);
  const poseRef = useRef<Pose | null>(null);
  const [searchParams] = useSearchParams();

  // íƒ€ì´ë¨¸/ì˜¤ë””ì˜¤/ëœë“œë§ˆí¬
  const poseWaitTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const nextStepTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const latestLandmarksRef = useRef<Landmark[] | null>(null);
  const isProcessingRef = useRef(false); // í‰ê°€ ì¤‘ë³µ ë°©ì§€

  // íƒ€ì´ë¨¸ ì •ë¦¬
  const clearAllTimers = useCallback(() => {
    if (poseWaitTimerRef.current) {
      clearTimeout(poseWaitTimerRef.current);
      poseWaitTimerRef.current = null;
    }
    if (nextStepTimerRef.current) {
      clearTimeout(nextStepTimerRef.current);
      nextStepTimerRef.current = null;
    }
  }, []);

  // TTS ì •ì§€
  const stopTTS = useCallback(() => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current.currentTime = 0;
      currentAudioRef.current = null;
    }
    setIsPlayingTTS(false);
  }, []);

  // TTS ì¬ìƒ
  const playTTS = useCallback(async (text: string): Promise<boolean> => {
    if (!text.trim() || !apiKey) return false;

    return new Promise((resolve) => {
      // ì´ì „ ì˜¤ë””ì˜¤ ì¢…ë£Œ (ë‹¤ìŒ ìŠ¤í… ì„¤ëª…ì´ ëŠê¸°ì§€ ì•Šë„ë¡ moveToNextStep ì „ì—ë§Œ í˜¸ì¶œë¨)
      stopTTS();
      setIsPlayingTTS(true);

      fetchGoogleTTS(text, apiKey)
        .then((audioContent) => {
          if (!audioContent) {
            setIsPlayingTTS(false);
            resolve(false);
            return;
          }
          const audio = new Audio(`data:audio/mp3;base64,${audioContent}`);
          currentAudioRef.current = audio;

          const handleEnded = () => {
            setIsPlayingTTS(false);
            currentAudioRef.current = null;
            resolve(true);
          };
          const handleError = () => {
            setIsPlayingTTS(false);
            currentAudioRef.current = null;
            resolve(false);
          };

          audio.addEventListener('ended', handleEnded);
          audio.addEventListener('error', handleError);
          audio.play().catch(handleError);
        })
        .catch(() => {
          setIsPlayingTTS(false);
          resolve(false);
        });
    });
  }, [apiKey, stopTTS]);

  // === 3ë‹¨ê³„: ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì´ë™ (ë¨¼ì € ì„ ì–¸!) ===
  const moveToNextStep = useCallback(() => {
    if (isProcessingRef.current) return;

    setCurrentPhase('loading');
    clearAllTimers();
    stopTTS(); // ì´ì „ í”¼ë“œë°±ì´ ëë‚œ ìƒíƒœì—ì„œ ì•ˆì „ ì •ë¦¬
    latestLandmarksRef.current = null;

    const nextIndex = currentStepIndex + 1;

    if (nextIndex >= poseSteps.length) {
      const nextSets = Math.min(sets + 1, MAX_DOTS);
      setSets(nextSets);
      setCurrentStepIndex(0);
      setStep(poseSteps[0]?.step_number || 1);
      if (poseSteps.length > 0) {
        setExerciseDesc(poseSteps[0].pose_description || 'í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
      }

      if (nextSets >= MAX_DOTS) {
        if (currentExerciseIndex + 1 < exercises.length) {
          setCurrentExerciseIndex(prev => prev + 1);
          setSets(0); // ìƒˆ ìš´ë™ ì‹œì‘
          return;
        } else {
          setShowPopup(true);
          setTimeout(() => navigate('/record'), 3000);
          return;
        }
      }
    } else {
      setCurrentStepIndex(nextIndex);
      setStep(poseSteps[nextIndex].step_number);
      if (poseSteps[nextIndex]) {
        setExerciseDesc(poseSteps[nextIndex].pose_description || 'í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
      }
    }
  }, [clearAllTimers, stopTTS, currentStepIndex, poseSteps, sets, currentExerciseIndex, exercises, navigate]);

  // 1ë‹¨ê³„: ìš´ë™ ì„¤ëª…
  const startDescriptionPhase = useCallback(async () => {
    if (!exerciseDesc || exerciseDesc === 'í¬ì¦ˆ ì„¤ëª…ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...') return;

    setCurrentPhase('description');
    clearAllTimers();
    latestLandmarksRef.current = null;

    await playTTS(exerciseDesc);
    // ì„¤ëª… ëë‚¬ìœ¼ë©´ 10ì´ˆ ëŒ€ê¸° ì‹œì‘
    setCurrentPhase('waiting');
    poseWaitTimerRef.current = setTimeout(() => {
      evaluatePoseAndGiveFeedback();
    }, POSE_WAIT_TIME);
  }, [exerciseDesc, clearAllTimers, playTTS]);

  // 2ë‹¨ê³„: ìì„¸ í‰ê°€ & í”¼ë“œë°± (ì˜¤ë‹µì´ë©´ 10ì´ˆ ëŒ€ê¸° ë°˜ë³µ, ì •ë‹µì´ë©´ 3ì´ˆ í›„ ë‹¤ìŒ)
  const evaluatePoseAndGiveFeedback = useCallback(async () => {
    if (isProcessingRef.current) return;
    isProcessingRef.current = true;

    setCurrentPhase('feedback');
    clearAllTimers();

    const requeueWait = () => {
      // ì˜¤ë‹µ/ë¯¸ì¸ì‹/ì˜¤ë¥˜ â†’ 10ì´ˆ í›„ ë‹¤ì‹œ í‰ê°€ ë£¨í”„
      setCurrentPhase('waiting');
      latestLandmarksRef.current = null; // ìƒˆë¡œ ìº¡ì²˜í•˜ë„ë¡ ë¦¬ì…‹
      isProcessingRef.current = false;   // í‰ê°€ ê°€ëŠ¥ ìƒíƒœ ë³µêµ¬
      poseWaitTimerRef.current = setTimeout(() => {
        evaluatePoseAndGiveFeedback();
      }, POSE_WAIT_TIME);
    };

    try {
      let feedbackText = '';

      if (!latestLandmarksRef.current) {
        feedbackText = 'ì¹´ë©”ë¼ì—ì„œ ìì„¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ìì„¸ë¥¼ ì¡ì•„ë³¼ê²Œìš”.';
        await playTTS(feedbackText);
        requeueWait();
        return;
      }

      // í‚¤í¬ì¸íŠ¸ êµ¬ì„±
      const filteredKeypoints: Record<string, [number, number]> = {};
      for (const name of REQUIRED_KEYS) {
        const idx = (POSE_LANDMARKS as any)[name];
        const lm = latestLandmarksRef.current[idx];
        if (lm) filteredKeypoints[name] = [lm.x, lm.y];
      }

      const currentEx = exercises[currentExerciseIndex];
      if (!currentEx?.exercise_id) {
        await playTTS('ìš´ë™ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ë³¼ê²Œìš”.');
        requeueWait();
        return;
      }

      const response = await axios.post(
        'https://v-tune-be.onrender.com/api/compare/',
        { keypoints: filteredKeypoints },
        {
          params: { exercise_id: currentEx.exercise_id, step_number: step },
          headers: { "Content-Type": "application/json" },
          timeout: 8000
        }
      );

      const match = !!response.data?.match;
      feedbackText = response.data.feedback_text ||
                     response.data.ck_text ||
                     (match ? "ì™„ë²½í•´ìš”! ìì„¸ê°€ ì •í™•í•©ë‹ˆë‹¤!" : "ì¡°ê¸ˆë§Œ ë”! ë°©ê¸ˆ ì•ˆë‚´í•œ ë¶€ë¶„ì„ ì‹ ê²½ ì¨ì£¼ì„¸ìš”.");

      await playTTS(feedbackText);

      if (match) {
        // ì •ë‹µ â†’ 3ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ë‹¨ê³„
        setCurrentPhase('moving');
        isProcessingRef.current = false;
        nextStepTimerRef.current = setTimeout(() => {
          moveToNextStep();
        }, NEXT_STEP_WAIT_TIME);
      } else {
        // ì˜¤ë‹µ â†’ ë‹¤ì‹œ 10ì´ˆ ëŒ€ê¸° í›„ ì¬í‰ê°€
        requeueWait();
      }
    } catch (e) {
      await playTTS('ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ë¹„êµë¥¼ ì™„ë£Œí•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ë³¼ê²Œìš”.');
      requeueWait();
    }
  }, [exercises, currentExerciseIndex, step, playTTS, clearAllTimers, moveToNextStep]);

  // ì„¤ëª…ì´ ì¤€ë¹„ë˜ë©´ ìë™ ì‹œì‘
  useEffect(() => {
    if (currentPhase === 'loading' && exerciseDesc && exerciseDesc !== 'í¬ì¦ˆ ì„¤ëª…ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...') {
      const t = setTimeout(() => startDescriptionPhase(), 400);
      return () => clearTimeout(t);
    }
  }, [currentPhase, exerciseDesc, startDescriptionPhase]);

  // ìš´ë™/ìŠ¤í… ë°ì´í„° ë¡œë”©
  useEffect(() => {
    const routineId = searchParams.get('routineId');
    if (!routineId) return;

    const fetchData = async () => {
      try {
        const response = await axios.get(
          `https://v-tune-be.onrender.com/api/routines/${routineId}/exercises/`
        );
        const exerciseList = response.data.exercises;
        if (Array.isArray(exerciseList) && exerciseList.length > 0) {
          setExercises(exerciseList);
          const currentExercise = exerciseList[currentExerciseIndex];
          setExerciseName(currentExercise?.name || 'ìš´ë™ ì´ë¦„ ì—†ìŒ');
          await loadPoseSteps(currentExercise.exercise_id);
        }
      } catch (error) {
        console.error('[DATA] ë¡œë”© ì‹¤íŒ¨:', error);
      }
    };

    fetchData();
  }, [searchParams, currentExerciseIndex]);

  const loadPoseSteps = async (exerciseId: number) => {
    try {
      const response = await axios.get(
        `https://v-tune-be.onrender.com/api/data/pose-steps/?exercise_id=${exerciseId}`
      );

      if (Array.isArray(response.data) && response.data.length > 0) {
        const steps = response.data;
        setPoseSteps(steps);
        setCurrentStepIndex(0);
        setStep(steps[0].step_number);
        setExerciseDesc(steps[0].pose_description || 'í¬ì¦ˆ ì„¤ëª… ì—†ìŒ');
        setCurrentPhase('loading');
        if (currentExerciseIndex > 0) setSets(0);
      }
    } catch (error) {
      console.error('[DATA] í¬ì¦ˆ ìŠ¤í… ë¡œë”© ì‹¤íŒ¨:', error);
    }
  };

  // Pose ê²°ê³¼ ì²˜ë¦¬ (ìŠ¤ì¼ˆë ˆí†¤ë§Œ)
  const onResults = useCallback(async (results: Results) => {
    if (!results.poseLandmarks) return;

    if (currentPhase === 'waiting') {
      latestLandmarksRef.current = results.poseLandmarks;
    }

    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    const video = webcamRef.current?.video;
    if (!ctx || !canvas || !video) return;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    ctx.strokeStyle = '#6d88e8ff';
    ctx.lineWidth = 2;
    for (const [startIdx, endIdx] of POSE_CONNECTIONS) {
      const start = results.poseLandmarks[startIdx];
      const end = results.poseLandmarks[endIdx];
      if (!start || !end) continue;
      ctx.beginPath();
      ctx.moveTo(start.x * canvas.width, start.y * canvas.height);
      ctx.lineTo(end.x * canvas.width, end.y * canvas.height);
      ctx.stroke();
    }
    ctx.fillStyle = '#6d88e8ff';
    for (const pt of results.poseLandmarks) {
      ctx.beginPath();
      ctx.arc(pt.x * canvas.width, pt.y * canvas.height, 4, 0, 2 * Math.PI);
      ctx.fill();
    }
  }, [currentPhase]);

  // Pose ì„¤ì •
  const onResultsRef = useRef<(r: Results) => void>(() => {});
  useEffect(() => { onResultsRef.current = onResults; }, [onResults]);

  useEffect(() => {
    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    pose.onResults((res: Results) => onResultsRef.current(res));
    poseRef.current = pose;

    return () => {
      poseRef.current?.close();
      poseRef.current = null;
    };
  }, []);

  // ì¹´ë©”ë¼
  useEffect(() => {
    const startCamera = () => {
      if (webcamRef.current?.video && poseRef.current) {
        cameraRef.current = new cam.Camera(webcamRef.current.video, {
          onFrame: async () => {
            if (poseRef.current && webcamRef.current?.video) {
              await poseRef.current.send({ image: webcamRef.current.video });
            }
          },
          width: 640,
          height: 480,
        });
        cameraRef.current.start();
      }
    };
    startCamera();
    return () => {
      cameraRef.current?.stop();
      cameraRef.current = null;
    };
  }, [facingMode]);

  const toggleCamera = useCallback(() => {
    setFacingMode(prev => (prev === "user" ? "environment" : "user"));
  }, []);

  // ì–¸ë§ˆìš´íŠ¸ ì •ë¦¬
  useEffect(() => {
    return () => {
      clearAllTimers();
      stopTTS();
    };
  }, [clearAllTimers, stopTTS]);

  return (
    <div className="stretch-container">
      <div className="top-bar">
        <button onClick={() => navigate('/')}>
          <img src={prevIcon} alt="Previous" />
        </button>
        <h2>{exerciseName}</h2>
      </div>

      <div className="camera-card" onClick={toggleCamera}>
        <div className="camera-wrapper">
          <Webcam
            key={facingMode}
            ref={webcamRef}
            className="camera"
            videoConstraints={{ facingMode }}
          />
          <canvas
            ref={canvasRef}
            className="pose-canvas"
            style={{
              position: 'absolute',
              top: 0,
              left: 0,
              zIndex: 2,
              width: '100%',
              height: '100%',
              pointerEvents: 'none',
            }}
          />
          <div className="overlay-box">
            <div className="set-count">
              <div className="dots">
                {[...Array(Math.min(sets, MAX_DOTS))].map((_, i) => (
                  <div key={i} className="dot" />
                ))}
              </div>
              <div className="reps">Step<br />{step}</div>
            </div>
          </div>
          {showPopup && <Popup />}
        </div>
      </div>

      <div className="description-balloon">
        <img src={personIcon} alt="person" className="person-icon" />
        <div className="custom-balloon">
          {exerciseDesc}
          {isPlayingTTS && <div className="playing-indicator">ğŸ”Š</div>}
          <div style={{ fontSize: '10px', color: '#888', marginTop: '5px' }}>
            ìƒíƒœ: {currentPhase === 'description' ? 'ì„¤ëª… ì¤‘' : 
                  currentPhase === 'waiting' ? 'ìì„¸ ëŒ€ê¸° ì¤‘' :
                  currentPhase === 'feedback' ? 'í”¼ë“œë°± ì¤‘' :
                  currentPhase === 'moving' ? 'ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„ ì¤‘' : 'ë¡œë”© ì¤‘'}
          </div>
        </div>
      </div>
    </div>
  );
};

export default StretchScreen;